{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Batch_5064543_batch_results_50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HITId', 'HITTypeId', 'Title', 'Description', 'Keywords', 'Reward',\n",
      "       'CreationTime', 'MaxAssignments', 'RequesterAnnotation',\n",
      "       'AssignmentDurationInSeconds', 'AutoApprovalDelayInSeconds',\n",
      "       'Expiration', 'NumberOfSimilarHITs', 'LifetimeInSeconds',\n",
      "       'AssignmentId', 'WorkerId', 'AssignmentStatus', 'AcceptTime',\n",
      "       'SubmitTime', 'AutoApprovalTime', 'ApprovalTime', 'RejectionTime',\n",
      "       'RequesterFeedback', 'WorkTimeInSeconds', 'LifetimeApprovalRate',\n",
      "       'Last30DaysApprovalRate', 'Last7DaysApprovalRate', 'Input.id',\n",
      "       'Input.stimulus_id', 'Input.utterance', 'Input.correct_guess',\n",
      "       'Input.speaker_id', 'Input.listener_id', 'Input.scan_id',\n",
      "       'Input.instance_type', 'Input.target_id', 'Input.tokens',\n",
      "       'Input.dataset', 'Input.mentions_target_class',\n",
      "       'Input.uses_object_lang', 'Input.uses_spatial_lang',\n",
      "       'Input.uses_color_lang', 'Input.uses_shape_lang', 'Answer.object1',\n",
      "       'Answer.object2', 'Answer.object3', 'Answer.object4', 'Answer.object5',\n",
      "       'Answer.object6', 'Answer.object7', 'Answer.object8', 'Answer.order1',\n",
      "       'Answer.order2', 'Answer.order3', 'Answer.order4', 'Answer.order5',\n",
      "       'Answer.order6', 'Answer.order7', 'Answer.order8', 'Approve', 'Reject'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe needed columns for querying: \\n    1. HITTId-> The unique ID for the sentence \\n    2. Input.utterance -> Sentence\\n    3. Input.Instance  -> Target\\n    4. ِ[Answer.object1, Answer.object8] -> Objects\\n    5. [Answer.order1, Answer.order8] -> Order\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "'''\n",
    "The needed columns for querying: \n",
    "    1. HITTId-> The unique ID for the sentence \n",
    "    2. Input.utterance -> Sentence\n",
    "    3. Input.Instance  -> Target\n",
    "    4. ِ[Answer.object1, Answer.object8] -> Objects\n",
    "    5. [Answer.order1, Answer.order8] -> Order\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Taking into account the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n",
      "{\"[(2, 'door'), (1, 'room')]\": 1, \"[(1, 'door'), (2, 'room')]\": 1, \"[(2, 'door'), (1, 'doors')]\": 1, \"[(1, 'doors'), (2, 'door')]\": 1}   {\"[(1, 'room'), (2, 'door')]\": 1, \"[(1, 'door'), (2, 'room')]\": 1, \"[(1, 'doors'), (2, 'door')]\": 2}\n"
     ]
    }
   ],
   "source": [
    "#TODO 1: Check whether all Annotation have the same order or not \n",
    "\n",
    "#Get Unique HITTId\n",
    "unique_HITTId = df['HITId'].unique()\n",
    "total_number_of_examples = df.shape[0]\n",
    "\n",
    "df_copy = df.copy()\n",
    "\n",
    "order_is_wrong_by_all_HITTId = []\n",
    "df_copy = df_copy.sort_values(by=['HITId'])\n",
    "\n",
    "#Mapper to know the number of HITTId for each sentence \n",
    "sentence_Num_HTTHId_mapper = {}\n",
    "\n",
    "for i in range(total_number_of_examples):\n",
    "    if df_copy['HITId'].iloc[i] not in sentence_Num_HTTHId_mapper:\n",
    "        sentence_Num_HTTHId_mapper[df_copy['HITId'].iloc[i]] = 1\n",
    "    else:\n",
    "        sentence_Num_HTTHId_mapper[df_copy['HITId'].iloc[i]] += 1\n",
    "        \n",
    "#Check whether all Annotation have the same order or not for each HITTId\n",
    "\n",
    "Number_of_agreements_per_HITTId_for_both_flexible= {}  \n",
    "Number_of_agreements_per_HITTId_for_both_strict = {}\n",
    "idx = 0\n",
    "while(idx < 1):\n",
    "\n",
    "    both_list    = set()\n",
    "    both_list_strict = set()\n",
    "\n",
    "    both_count = {}\n",
    "    both_count_strict = {}\n",
    "    i = idx \n",
    "    stop_at = i + sentence_Num_HTTHId_mapper[df_copy['HITId'].iloc[i]]\n",
    "    print(i, stop_at)\n",
    "    while(i < stop_at):\n",
    "        \n",
    "        Answers_generically  = []\n",
    "        Answers_generically_strict = []\n",
    "        for j in range(1,9):\n",
    "            feature1 = 'Answer.order' + str(j)\n",
    "            feature2 = 'Answer.object' + str(j)\n",
    "                              \n",
    "            if str(df_copy[feature2].iloc[i]) != 'nan' and str(df_copy[feature1].iloc[i]) != 'nan':\n",
    "                object_ = str(df_copy[feature2].iloc[i])\n",
    "                object_ = object_.lower()\n",
    "                import string\n",
    "                object_ = object_.translate(str.maketrans('', '', string.punctuation))\n",
    "                #TODO: Make it more flexiable\n",
    "                object_ = object_.split(\" \")[-1]\n",
    "                try:\n",
    "                    Answers_generically.append((int(df_copy[feature1].iloc[i]), str(object_)))\n",
    "                    Answers_generically_strict.append((int(df_copy[feature1].iloc[i]), str(object_)))\n",
    "                except: \n",
    "                    print(\"I WILL NOT ADD THIS BECAUSE OF THE ERROR: \", df_copy['HITId'].iloc[i])\n",
    "\n",
    "        \n",
    "        #Order Answers_for_each_annotator_by_order\n",
    "        # Answers_for_each_annotator_by_order.sort()\n",
    "        # Answers_for_each_annotator_by_object.sort()\n",
    "        # print(Answers_generically)\n",
    "        # Answers_generically_strict = Answers_generically.copy()\n",
    "        Answers_generically.sort() #Sort by order then object\n",
    "        \n",
    "        if (str(Answers_generically_strict) not in both_count_strict):\n",
    "            both_count_strict[str(Answers_generically_strict)] = 1\n",
    "        else:\n",
    "            both_count_strict[str(Answers_generically_strict)] += 1\n",
    "            \n",
    "            \n",
    "        \n",
    "        if(str(Answers_generically) not in both_count):\n",
    "            both_count[str(Answers_generically)] = 1\n",
    "        else:\n",
    "            both_count[str(Answers_generically)] += 1\n",
    "            \n",
    "        both_list.add(str(Answers_generically))\n",
    "        both_list_strict.add(str(Answers_generically_strict))\n",
    "        i+=1\n",
    "        \n",
    "    #Get the maximum Voting for each using otdered_list and ordere_list_count\n",
    "    max_for_both = 0\n",
    "    max_for_both_strict = 0\n",
    "    \n",
    "    print(both_count_strict, ' ' , both_count)\n",
    "    for both in both_count_strict:\n",
    "        max_for_both_strict = max(max_for_both_strict, both_count_strict[both])\n",
    "    \n",
    "    for both in both_count:\n",
    "        max_for_both = max(max_for_both, both_count[both])\n",
    "        \n",
    "    \n",
    "    #Add it to the agreement \n",
    "    if sentence_Num_HTTHId_mapper[df_copy['HITId'].iloc[idx]] == 4:\n",
    "        Number_of_agreements_per_HITTId_for_both_flexible[df_copy['HITId'].iloc[idx]] = max_for_both\n",
    "        Number_of_agreements_per_HITTId_for_both_strict[df_copy['HITId'].iloc[idx]] = max_for_both_strict\n",
    "    \n",
    "    \n",
    "    idx += sentence_Num_HTTHId_mapper[df_copy['HITId'].iloc[idx]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Does not Follow the order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences_done_with_4_annotators:  1650\n",
      "sentences_done_with_3_annotators:  160\n"
     ]
    }
   ],
   "source": [
    "#TODO 2: \n",
    "    #how many samples are completed fully (by 4 annotators) and how many samples are completed by only 3 annotators?\n",
    "\n",
    "#Using sentence_Num_HTTHId_mapper\n",
    "\n",
    "sentences_done_with_4_annotators = 0\n",
    "sentences_done_with_3_annotators = 0\n",
    "\n",
    "for sentence in sentence_Num_HTTHId_mapper:\n",
    "    if sentence_Num_HTTHId_mapper[sentence] == 4:\n",
    "        sentences_done_with_4_annotators += 1\n",
    "    elif sentence_Num_HTTHId_mapper[sentence] == 3:\n",
    "        sentences_done_with_3_annotators += 1\n",
    "        \n",
    "\n",
    "print(\"sentences_done_with_4_annotators: \", sentences_done_with_4_annotators)\n",
    "print(\"sentences_done_with_3_annotators: \", sentences_done_with_3_annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2692"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_Num_HTTHId_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage_4_0_agreement:  0.4593939393939394\n",
      "precentage_3_1_agreement:  0.25333333333333335\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO 3: The Percange for each case: Flexible \n",
    "percentage_4_0_agreement = 0 \n",
    "precentage_3_1_agreement = 0\n",
    "\n",
    "for sentence in Number_of_agreements_per_HITTId_for_both_flexible:\n",
    "    if Number_of_agreements_per_HITTId_for_both_flexible[sentence] == 4:\n",
    "        percentage_4_0_agreement += 1\n",
    "    elif Number_of_agreements_per_HITTId_for_both_flexible[sentence] == 3:\n",
    "        precentage_3_1_agreement += 1\n",
    "\n",
    "print(\"percentage_4_0_agreement: \", percentage_4_0_agreement/sentences_done_with_4_annotators)\n",
    "print(\"precentage_3_1_agreement: \", precentage_3_1_agreement/sentences_done_with_4_annotators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7127272727272728"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4593939393939394 + 0.25333333333333335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Agreements with 4 annotators:  758\n",
      "Number of Agreements with 3 annotators:  418\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Agreements with 4 annotators: \", percentage_4_0_agreement)\n",
    "print(\"Number of Agreements with 3 annotators: \", precentage_3_1_agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage_4_0_agreement:  0.4309090909090909\n",
      "precentage_3_1_agreement:  0.2381818181818182\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO 3: The Percange for each case: Strict \n",
    "percentage_4_0_agreement = 0 \n",
    "precentage_3_1_agreement = 0\n",
    "\n",
    "for sentence in  Number_of_agreements_per_HITTId_for_both_strict:\n",
    "    if Number_of_agreements_per_HITTId_for_both_strict[sentence] == 4:\n",
    "        percentage_4_0_agreement += 1\n",
    "    elif Number_of_agreements_per_HITTId_for_both_strict[sentence] == 3:\n",
    "        precentage_3_1_agreement += 1\n",
    "\n",
    "print(\"percentage_4_0_agreement: \", percentage_4_0_agreement/sentences_done_with_4_annotators)\n",
    "print(\"precentage_3_1_agreement: \", precentage_3_1_agreement/sentences_done_with_4_annotators)\n",
    "# print(precentage_3_1_agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Agreements with 4 annotators:  711\n",
      "Number of Agreements with 3 annotators:  393\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Agreements with 4 annotators: \", percentage_4_0_agreement)\n",
    "print(\"Number of Agreements with 3 annotators: \", precentage_3_1_agreement)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3QREJ3J433GK5HZ84AAP6VPESRLKLZ'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "df_copy['HITId'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n",
      "[[('1', \"'room'\", '0'), ('2', \"'door'\", '0')], [('1', \"'door'\", '1'), ('2', \"'center of room'\", '1')], [('1', \"'doors'\", '2'), ('2', \"'door'\", '2')], [('1', \"'doors'\", '3'), ('2', \"'door'\", '3')]]\n",
      "[[('2', \"'door'\", '0'), ('1', \"'room'\", '0')], [('1', \"'door'\", '1'), ('2', \"'center of room'\", '1')], [('2', \"'door'\", '2'), ('1', \"'doors'\", '2')], [('1', \"'doors'\", '3'), ('2', \"'door'\", '3')]]\n",
      "[\"'room'\", \"'door'\"] [\"'door'\", \"'room'\"]\n",
      "second_max_for_both:  1 second_max_for_both_strict:  0\n"
     ]
    }
   ],
   "source": [
    "# #FOR SUBSTRING: WOTKING ON IT: \n",
    "# #TODO 1: Check whether all Annotation have the same order or not \n",
    "\n",
    "# #Get Unique HITTId\n",
    "# unique_HITTId = df['HITId'].unique()\n",
    "# total_number_of_examples = df.shape[0]\n",
    "\n",
    "# df_copy = df.copy()\n",
    "\n",
    "# order_is_wrong_by_all_HITTId = []\n",
    "# df_copy = df_copy.sort_values(by=['HITId'])\n",
    "\n",
    "# #Mapper to know the number of HITTId for each sentence \n",
    "# sentence_Num_HTTHId_mapper = {}\n",
    "\n",
    "# for i in range(total_number_of_examples):\n",
    "#     if df_copy['HITId'].iloc[i] not in sentence_Num_HTTHId_mapper:\n",
    "#         sentence_Num_HTTHId_mapper[df_copy['HITId'].iloc[i]] = 1\n",
    "#     else:\n",
    "#         sentence_Num_HTTHId_mapper[df_copy['HITId'].iloc[i]] += 1\n",
    "        \n",
    "# #Check whether all Annotation have the same order or not for each HITTId\n",
    "\n",
    "# Number_of_agreements_per_HITTId_for_both_flexible= {}  \n",
    "# Number_of_agreements_per_HITTId_for_both_strict = {}\n",
    "# idx = 0\n",
    "# while(idx < 1):\n",
    "\n",
    "#     both_list    = set()\n",
    "#     both_list_strict = set()\n",
    "\n",
    "#     both_count = {}\n",
    "#     both_count_strict = {}\n",
    "#     i = idx \n",
    "#     stop_at = i + sentence_Num_HTTHId_mapper[df_copy['HITId'].iloc[i]]\n",
    "#     print(i, stop_at)\n",
    "#     while(i < stop_at):\n",
    "#         Answers_generically  = []\n",
    "#         Answers_generically_strict = []\n",
    "#         for j in range(1,9):\n",
    "#             feature1 = 'Answer.order' + str(j)\n",
    "#             feature2 = 'Answer.object' + str(j)\n",
    "                              \n",
    "#             if str(df_copy[feature2].iloc[i]) != 'nan' and str(df_copy[feature1].iloc[i]) != 'nan':\n",
    "#                 object_ = str(df_copy[feature2].iloc[i])\n",
    "#                 object_ = object_.lower()\n",
    "                \n",
    "#                 import string\n",
    "#                 object_ = object_.translate(str.maketrans('', '', string.punctuation))\n",
    "#                 #TODO: Make it more flexiable\n",
    "#                 try:\n",
    "#                     Answers_generically.append((int(df_copy[feature1].iloc[i]), str(object_), i))\n",
    "#                     Answers_generically_strict.append((int(df_copy[feature1].iloc[i]), str(object_), i))\n",
    "#                 except: \n",
    "#                     print(\"I WILL NOT ADD THIS BECAUSE OF THE ERROR: \", df_copy['HITId'].iloc[i])\n",
    "\n",
    "        \n",
    "#         Answers_generically.sort() #Sort by order then object\n",
    "        \n",
    "#         if (str(Answers_generically_strict) not in both_count_strict):\n",
    "#             both_count_strict[str(Answers_generically_strict)] = 1\n",
    "#         else:\n",
    "#             both_count_strict[str(Answers_generically_strict)] += 1\n",
    "            \n",
    "        \n",
    "#         if(str(Answers_generically) not in both_count):\n",
    "#             both_count[str(Answers_generically)] = 1\n",
    "#         else:\n",
    "#             both_count[str(Answers_generically)] += 1\n",
    "            \n",
    "#         both_list.add(str(Answers_generically))\n",
    "#         both_list_strict.add(str(Answers_generically_strict))\n",
    "#         i+=1\n",
    "        \n",
    "#     #Get the maximum Voting for each using otdered_list and ordere_list_count\n",
    "#     max_for_both = 0\n",
    "#     max_for_both_strict = 0\n",
    "#     which_idx_strict = -1\n",
    "#     which_idx_flexible = -1\n",
    "    \n",
    "#     for both in both_count_strict:\n",
    "#         if max_for_both_strict < both_count_strict[both]:\n",
    "#             max_for_both_strict = both_count_strict[both]\n",
    "#             which_idx_strict = both.split(\",\")[-1][:-2]\n",
    "    \n",
    "#     for both in both_count:\n",
    "#         if max_for_both < both_count[both]:\n",
    "#             max_for_both = both_count[both]\n",
    "#             which_idx_flexible = both.split(\",\")[-1][:-2]\n",
    "    \n",
    "#     best_flexible = []\n",
    "#     best_strict   = []\n",
    "#     for key in list(both_count.keys()):\n",
    "#         list_ = key.strip('][').split(', ')\n",
    "#         #Strip the tuple\n",
    "#         tuples = ()\n",
    "#         res_list = []\n",
    "#         list_idx = 0\n",
    "#         for  x in list_:\n",
    "#             tuple_ = x.strip('()').split(',')\n",
    "#             tuples += (tuple_[0],)\n",
    "#             list_idx+=1\n",
    "#             if (list_idx%3 == 0):\n",
    "#                 res_list.append(tuples)\n",
    "#                 tuples = ()\n",
    "#         best_flexible.append(res_list)\n",
    "        \n",
    "#     for key in list(both_count_strict.keys()):\n",
    "#         list_ = key.strip('][').split(', ')\n",
    "#         #Strip the tuple\n",
    "#         tuples = ()\n",
    "#         res_list = []\n",
    "#         list_idx = 0\n",
    "#         for  x in list_:\n",
    "#             tuple_ = x.strip('()').split(',')\n",
    "#             tuples += (tuple_[0],)\n",
    "#             list_idx+=1\n",
    "#             if (list_idx%3 == 0):\n",
    "#                 res_list.append(tuples)\n",
    "#                 tuples = ()\n",
    "#         best_strict.append(res_list)\n",
    "    \n",
    "#     print(best_flexible)\n",
    "#     print(best_strict)\n",
    "    \n",
    "#     #get objects from the best_flexible and best_strict\n",
    "    \n",
    "#     flexible_objects = []\n",
    "#     for i in range(len(best_flexible[int(which_idx_flexible)])):\n",
    "#         flexible_objects.append(best_flexible[int(which_idx_flexible)][i][1])\n",
    "        \n",
    "#     strict_objects   = []\n",
    "#     for i in range(len(best_strict[int(which_idx_strict)])):\n",
    "#         strict_objects.append(best_strict[int(which_idx_strict)][i][1])\n",
    "\n",
    "#     print(flexible_objects, strict_objects)\n",
    "    \n",
    "#     #Check with the substrings\n",
    "#     second_max_for_both = 0\n",
    "#     second_max_for_both_strict = 0\n",
    "#     for i, flexible_list in enumerate(best_flexible):\n",
    "#         if(i == which_idx_flexible):\n",
    "#                 continue \n",
    "#         objects = [flexible_list[i][1] for i in range(len(flexible_list))]\n",
    "#         temp_max = 0\n",
    "#         for obj1 in objects:\n",
    "#             for best_obj in flexible_objects:\n",
    "#                 if obj1 in best_obj or best_obj in obj1:\n",
    "#                     temp_max += 1\n",
    "        \n",
    "#         if temp_max == len(objects):\n",
    "#             second_max_for_both += 1\n",
    "        \n",
    "#     #Check with the substrings: Strict\n",
    "    \n",
    "#     for i, strict_list in enumerate(best_strict):\n",
    "        \n",
    "#         if(i == which_idx_strict):\n",
    "#                 continue \n",
    "        \n",
    "#         objects = strict_list[1]\n",
    "#         temp_max = 0\n",
    "#         for obj1 in objects:\n",
    "#             for best_obj in strict_objects:\n",
    "#                 if obj1 in best_obj or best_obj in obj1:\n",
    "#                     temp_max += 1\n",
    "        \n",
    "#         if temp_max == len(objects):\n",
    "#             second_max_for_both_strict += 1\n",
    "    \n",
    "#     print(\"second_max_for_both: \", second_max_for_both, \"second_max_for_both_strict: \", second_max_for_both_strict)\n",
    "    \n",
    "#     #Add it to the agreement \n",
    "#     if sentence_Num_HTTHId_mapper[df_copy['HITId'].iloc[idx]] == 4:\n",
    "#         Number_of_agreements_per_HITTId_for_both_flexible[df_copy['HITId'].iloc[idx]] = max_for_both\n",
    "#         Number_of_agreements_per_HITTId_for_both_strict[df_copy['HITId'].iloc[idx]] = max_for_both_strict\n",
    "    \n",
    "    \n",
    "#     idx += sentence_Num_HTTHId_mapper[df_copy['HITId'].iloc[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cot3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
