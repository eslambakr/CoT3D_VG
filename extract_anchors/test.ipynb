{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrem/3d_codes/CoT3D_VG/extract_anchors/referit3d/in_out/scannet_scan.py:97: UserWarning: scene0009_00 has some issue\n",
      "  warnings.warn('{} has some issue'.format(self.scan_id))\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from referit3d.in_out.scannet_scan import ScannetScan, ScannetDataset\n",
    "import pandas as pd\n",
    "import string\n",
    "#from extract_objs_from_description import ExtractObjsFromDescription\n",
    "import glob\n",
    "import numpy as np\n",
    "from benchmark_auto_obj_extraction_module_sr3d import read_referring_data_scv\n",
    "import multiprocessing as mp\n",
    "import math\n",
    "import json\n",
    "from extraction_utils import *\n",
    "\n",
    "\n",
    "def get3d_box_from_pcs(pc):\n",
    "    \"\"\"\n",
    "    Given point-clouds that represent object or scene return the 3D dimension of the 3D box that contains the PCs.\n",
    "    \"\"\"\n",
    "    w = pc[:, 0].max() - pc[:, 0].min()\n",
    "    l = pc[:, 1].max() - pc[:, 1].min()\n",
    "    h = pc[:, 2].max() - pc[:, 2].min()\n",
    "    return w, l, h\n",
    "\n",
    "\n",
    "def get3d_box_center_from_pcs(pc):\n",
    "    \"\"\"\n",
    "    Given point-clouds that represent object or scene return the 3D center of the 3D box that contains the PCs.\n",
    "    \"\"\"\n",
    "    w, l, h = get3d_box_from_pcs(pc)\n",
    "    return np.array([pc[:, 0].max() - w / 2, pc[:, 1].max() - l / 2, pc[:, 2].max() - h / 2])\n",
    "\n",
    "\n",
    "def extract_target_loc_from_pred_objs_from_description(pred_objs_list, target_class):\n",
    "    indices = [c for c, x in enumerate(pred_objs_list) if x == target_class]  # find indices of the target class\n",
    "    if len(indices) == 1:\n",
    "        return indices[0]\n",
    "    else:  # multiple targets have been found.\n",
    "        # TODO: Eslam: think about a way to find which one is the target.\n",
    "        # print(\"XXX for now will return the first occurrence\")\n",
    "        return indices[-1]  # for now will return the first occurrence\n",
    "\n",
    "\n",
    "def scannet_loader(scan_id):\n",
    "    \"\"\"Helper function to load the scans in memory.\n",
    "    :param scan_id:\n",
    "    :return: the loaded scan.\n",
    "    \"\"\"\n",
    "    global scannet\n",
    "\n",
    "    # print(\"scan_id = \", scan_id)\n",
    "    scan_i = ScannetScan(scan_id=scan_id, scannet_dataset=scannet, apply_global_alignment=False, load_dense=load_dense)\n",
    "    if load_dense:\n",
    "        scan_i.load_point_clouds_of_all_objects_dense()\n",
    "    else:\n",
    "        scan_i.load_point_clouds_of_all_objects()\n",
    "\n",
    "    return scan_i\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = read_referring_data_scv(file_path=\"nr3d_cot_ref_paraphrases.csv\")\n",
    "    scan_ids = df.scan_id\n",
    "    # Configurations:\n",
    "    # ---------------\n",
    "    load_dense = False\n",
    "    scannet_dataset_path = \"../../scannet_dataset/\"\n",
    "    # scannet_dataset_path = \"/media/eslam/0d208863-5cdb-4a43-9794-3ca8726831b3/3D_visual_grounding/dataset/\"\n",
    "\n",
    "    # Read the scan related information\n",
    "    top_scan_dir = scannet_dataset_path + \"scannet/scans\"\n",
    "    idx_to_semantic_class_file = '../automatic_loc_module/referit3d/data/mappings/scannet_idx_to_semantic_class.json'\n",
    "    instance_class_to_semantic_class_file = '../automatic_loc_module/referit3d/data/mappings/scannet_instance_class_to_semantic_class.json'\n",
    "    axis_alignment_info_file = '../automatic_loc_module/referit3d/data/scannet/scans_axis_alignment_matrices.json'\n",
    "    scannet = ScannetDataset(top_scan_dir,\n",
    "                             idx_to_semantic_class_file,\n",
    "                             instance_class_to_semantic_class_file,\n",
    "                             axis_alignment_info_file)\n",
    "    # Loop on the whole scenes and load them once:\n",
    "    all_scenes_paths = glob.glob(top_scan_dir+\"/*\")\n",
    "    all_scenes_paths = list(np.unique(np.array(scan_ids)))\n",
    "    scenes_dict = {}\n",
    "    all_scan_ids = all_scenes_paths\n",
    "    n_items = len(all_scan_ids)\n",
    "    n_processes = min(mp.cpu_count(), n_items)\n",
    "    pool = mp.Pool(n_processes)\n",
    "    chunks = int(n_items / n_processes)\n",
    "\n",
    "    for i, data in enumerate(pool.imap(scannet_loader, all_scan_ids, chunksize=chunks)):\n",
    "        scenes_dict[all_scan_ids[i]] = data\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    \n",
    "    # Create our obj retrieval module:\n",
    "    # obj_extractor = ExtractObjsFromDescription(\"./data/scannet_instance_class_to_semantic_class.json\")\n",
    "    \n",
    "    with open('mapped_relation.json') as f:\n",
    "        mapped_relation = json.load(f)\n",
    "    relation_fn_dict = {\n",
    "        'near': nearest_3dobject,\n",
    "        'far': farthest_3dobject,\n",
    "        'right': right_3dobject,\n",
    "        'left': left_3dobject,\n",
    "        'on': on_3dobject,\n",
    "        'down': under_3dobject,\n",
    "        'front': front_3dobject,\n",
    "        'back': back_3dobject\n",
    "    }\n",
    "    reverse_relation_fn_dict = {\n",
    "        'near': nearest_3dobject,\n",
    "        'far': farthest_3dobject,\n",
    "        'right': left_3dobject,\n",
    "        'left': right_3dobject,\n",
    "        'on': under_3dobject,\n",
    "        'down': on_3dobject,\n",
    "        'front': back_3dobject,\n",
    "        'back': front_3dobject\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_relationship_between_2_objs(target_string, RELATIONS):\n",
    "        target_string = target_string.lower()\n",
    "        words_pred = []\n",
    "        for rel_word in RELATIONS:\n",
    "            # if rel_word in sub_phrase.split(\" \"):\n",
    "            if re.search(r'\\b%s\\b' % (re.escape(rel_word.lower())), target_string) is not None:\n",
    "                words_pred.append(rel_word)\n",
    "        if len(words_pred) == 0:\n",
    "             # search the other way around:\n",
    "            for rel_word in RELATIONS:\n",
    "                if re.search(r'\\b%s\\b' % (re.escape(target_string)), rel_word.lower()) is not None:\n",
    "                    words_pred.append(rel_word)\n",
    "        max_str = ''\n",
    "        max_len = 0\n",
    "        if len(words_pred) == 0:\n",
    "            # get the closest match by finding if the target is a substring of any of the relations:\n",
    "            for rel_word in RELATIONS:\n",
    "                if target_string in rel_word.lower() or rel_word.lower() in target_string:\n",
    "                    words_pred.append(rel_word)\n",
    "        for word in words_pred:\n",
    "            if len(word) > len(max_str):\n",
    "                 max_str = word\n",
    "        return max_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utterance:  The rear, left hand side pillow on the bed that is closest to the cabinets\n",
      "Target:  pillow\n",
      "path:  [\"bed\", \"cabinet\", \"pillow\"]\n",
      "anchor_ids:  [8, 12]\n",
      "paraphrases:  []\n",
      "----------------\n",
      "Obj  7 :  bed 7\n",
      "Obj  8 :  bed 8\n",
      "Obj  12 :  cabinet 12\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The rear, left hand side pillow on the bed that is closest to the cabinets'\n",
    "sentence = 'The pillow at the back on the right, on the bed closet to the heater.'\n",
    "sentence = 'The pillow that is closest to the air conditioning unit on the wall and that is behind another pillow.' # Counter is wrong in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41503 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utterance:  choose the coffee table farthest from the longest table and between three seater couch and arm chair\n",
      "Target:  table\n",
      "path:  [\"table\", \"couch\", \"armchair\", \"table\"]\n",
      "anchor_ids:  [-1, -1, 10]\n",
      "paraphrases:  [\"choose the coffee table farthest from the longest table and between a three-seater sofa and an armchair\", \"choose the coffee table farthest from the longest table and between a three-seater sofa and an arm chair\", \"choose the coffee table farthest from the longest table and between a three-seat couch and an armchair\", \"choose the coffee table farthest from the longest table and between a three-seat couch and an arm chair\", \"choose the coffee table farthest from the longest table and between a three-seater couch and an armchair\", \"choose the coffee table farthest from the longest table and between a three-seater couch and an arm chair\"]\n",
      "----------------\n",
      "Obj  1 :  armchair 1\n",
      "Obj  2 :  couch 2\n",
      "Obj  3 :  couch 3\n",
      "Obj  4 :  couch 4\n",
      "Obj  14 :  chair 14\n",
      "Obj  15 :  chair 15\n",
      "Obj  16 :  chair 16\n",
      "Obj  23 :  armchair 23\n",
      "Obj  25 :  chair 25\n",
      "Obj  26 :  chair 26\n",
      "Obj  27 :  chair 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41503/41503 [02:19<00:00, 297.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "num of all objects:  90543\n",
      "num of Target objects:  45.83788917972676\n",
      "num of Unique objects:  23.97313983411197\n",
      "num of Geometry objects:  15.57381575604961\n",
      "num of Random objects:  4.528235203163138\n",
      "num of No box objects:  10.086920026948523\n",
      "num of No anchors objects:  0.0\n",
      "---------------------\n",
      "num of all objects:  90543\n",
      "num of Target objects:  41503\n",
      "num of Unique objects:  21706\n",
      "num of Geometry objects:  14101\n",
      "num of Random objects:  4100\n",
      "num of No box objects:  9133\n",
      "num of No anchors objects:  0\n",
      "---------------------\n",
      "Check the total number:  True\n",
      "---------------------\n",
      "The Assigned anchors are:  3\n",
      "obj =  <referit3d.in_out.three_d_object.ThreeDObject object at 0x147d14db3f10>\n",
      "Obj  0 :  wall 14\n",
      "obj =  <referit3d.in_out.three_d_object.ThreeDObject object at 0x147d14db3e90>\n",
      "Obj  1 :  bookshelf 13\n",
      "obj =  <referit3d.in_out.three_d_object.ThreeDObject object at 0x147d14db3f90>\n",
      "Obj  2 :  chair 15\n"
     ]
    }
   ],
   "source": [
    "df = read_referring_data_scv(file_path=\"nr3d_cot_ref_paraphrases.csv\")\n",
    "scan_ids = df.scan_id\n",
    "# Manual Sampling:\n",
    "# ----------------\n",
    "sentence = 'there are two boxes on the floor near the copier. both are placed in front of a closed door, but the box you are looking for is closest to the door and on top of the second box.'\n",
    "#sentence = 'The pillow that is closest to the air conditioning unit on the wall and that is behind another pillow.'\n",
    "#i =  df.loc[df['utterance'] == sentence].index[0]\n",
    "i = 2529\n",
    "print(\"utterance: \", df['utterance'][i])\n",
    "print(\"Target: \", df['instance_type'][i])\n",
    "print(\"path: \", df['path'][i])\n",
    "print(\"anchor_ids: \", df['anchor_ids'][i])\n",
    "print(\"paraphrases: \", df['paraphrases'][i])\n",
    "scan_id = scan_ids[i]\n",
    "print(\"----------------\")\n",
    "for obj_count, obj in enumerate(scenes_dict[scan_id].three_d_objects):\n",
    "    if obj.instance_label in df['path'][i] and (obj.instance_label != df['instance_type'][i]):\n",
    "        print(\"Obj \", obj_count, \": \", obj.instance_label, obj.object_id)\n",
    "\n",
    "relations_df = pd.read_csv(\"relations_parsed.csv\")\n",
    "relations_df['used_obj'] = [False] * len(relations_df)\n",
    "relations_df['used_sub'] = [False] * len(relations_df)\n",
    "relations = relations_df[relations_df['id'] == i].drop_duplicates(subset=['object', 'subject', 'relation']).copy()\n",
    "#print(\"The whole relations in the sentence are: \", relations)\n",
    "\n",
    "gt_objs_name_all_scenes = []\n",
    "gt_utternaces_all_scenes = []\n",
    "pred_objs_name_all_scenes = []\n",
    "counter = 0\n",
    "unique_anchor_counter = 0\n",
    "empty_relation_counter = 0\n",
    "empty_anchor_counter = 0\n",
    "no_box_counter = 0\n",
    "target_mismatch_target = 0\n",
    "correct_counter = 0\n",
    "target_counter = 0\n",
    "unique_anchor_counter2 = 0\n",
    "empty_relation_counter2 = 0\n",
    "empty_anchor_counter2 = 0\n",
    "hard_counter = 0\n",
    "empty_anchor_flag = False\n",
    "empty_relation_flag = False\n",
    "unique_anchor_flag = False\n",
    "\n",
    "\n",
    "all_scene_anchors = {}\n",
    "all_scenes_refined_path = []\n",
    "all_scenes_num_anchors = []\n",
    "for i in tqdm(range(len(df))):\n",
    "#if True:\n",
    "    scan_id = scan_ids[i]\n",
    "    refined_path = json.loads(df['path'][i])\n",
    "    \n",
    "    # Refine the detected path:\n",
    "    if len(refined_path) == 0:\n",
    "        refined_path.append(df['instance_type'][i])\n",
    "    if df['instance_type'][i] != refined_path[-1]:\n",
    "        # The target should be the last object in the path if not force it\n",
    "        if df['instance_type'][i] in refined_path:\n",
    "            refined_path.remove(df['instance_type'][i])\n",
    "            refined_path.append(df['instance_type'][i])\n",
    "        else:  # if not exist at all, add it to the end\n",
    "            refined_path.append(df['instance_type'][i])\n",
    "    \n",
    "    all_scenes_refined_path.append(refined_path)\n",
    "\n",
    "    empty_anchor_flag = False\n",
    "    empty_relation_flag = False\n",
    "    unique_anchor_flag = False\n",
    "    # Run our obj retrieval module:\n",
    "    pred_objs_name = extract_objs_from_description(df.utterance[i], df.instance_type[i], refined_path)\n",
    "    all_scenes_num_anchors.append(len(pred_objs_name)-1)\n",
    "    # if len(pred_objs_name[-1]) >0 and  df.instance_type[i] != pred_objs_name[-1]:\n",
    "    #     target_mismatch_target += 1\n",
    "    trgt_idx = 9999\n",
    "    # possible_anchors_dict = {}  # clear the dictionary for each scene\n",
    "    all_scene_anchors[i] = [-1] * (len(pred_objs_name))\n",
    "\n",
    "    # if len(pred_objs_name) == 1 and pred_objs_name[0] == df.instance_type[i]:\n",
    "    #     # all_scene_anchors[i].append(-1)\n",
    "    #     no_anchor_counter_per_scene += 1\n",
    "\n",
    "    pred_objs_name_all_scenes.append(pred_objs_name)\n",
    "    # Extract easy objs; prior knowledge (the target and the unique objects):\n",
    "    pred_anchor = [None] * len(pred_objs_name)\n",
    "    possible_anchors_dict = {}  # clear the dictionary for each scene\n",
    "    for pred_obj_idx, pred_obj_name in enumerate(pred_objs_name):  # Loop on the predicted objects in the utterance\n",
    "        counter += 1\n",
    "        if '*' == pred_obj_name[0]:\n",
    "            no_box_counter += 1\n",
    "            continue\n",
    "        # Get all the possible objects that exist in the scene and match the predicted obj class from the text:\n",
    "        if not (pred_obj_name in possible_anchors_dict.keys()):\n",
    "            possible_anchors_dict[pred_obj_name] = []  # initialize the list once\n",
    "            for obj_3d in scenes_dict[scan_id].three_d_objects:\n",
    "                if (pred_obj_name == obj_3d.instance_label): # or (pred_obj_name in obj_3d.instance_label.split()) or (obj_3d.instance_label in pred_obj_name.split()):\n",
    "                    possible_anchors_dict[pred_obj_name].append(obj_3d)\n",
    "\n",
    "        # Exclude the target:\n",
    "        if pred_obj_name == df.instance_type[i]: # or pred_obj_name in df.instance_type[i] or df.instance_type[i] in pred_obj_name:\n",
    "            # Detect the target location from the predicted objects from the utterance:\n",
    "            obj_name = df.instance_type[i]\n",
    "            if pred_obj_name != df.instance_type[i]:\n",
    "                obj_name = pred_obj_name\n",
    "            target_idx = extract_target_loc_from_pred_objs_from_description(pred_objs_list=pred_objs_name,\n",
    "                                                                            target_class=obj_name)\n",
    "            if pred_obj_idx == target_idx:  # make sure it is the target not text-distractor\n",
    "                for anchor_id, anchor in enumerate(possible_anchors_dict[pred_obj_name]):\n",
    "                    if anchor.object_id == df.target_id[i]:\n",
    "                        target_counter += 1\n",
    "                        trgt_idx = target_idx\n",
    "                        target_anchor = possible_anchors_dict[pred_obj_name][anchor_id]\n",
    "                        pred_anchor[pred_obj_idx] = target_anchor\n",
    "                        del possible_anchors_dict[pred_obj_name][anchor_id]\n",
    "                        del all_scene_anchors[i][pred_obj_idx]\n",
    "                        break\n",
    "                continue\n",
    "        # import pdb; pdb.set_trace()\n",
    "        if len(possible_anchors_dict[pred_obj_name]) == 0:\n",
    "            print(\"XXX  Error the obj not found\",pred_obj_name, \"!!!\")\n",
    "            empty_anchor_counter += 1\n",
    "            empty_anchor_flag = True\n",
    "            continue\n",
    "        elif len(possible_anchors_dict[pred_obj_name]) == 1:  # Unique object\n",
    "            pred_anchor[pred_obj_idx] = possible_anchors_dict[pred_obj_name][0]\n",
    "            all_scene_anchors[i][pred_obj_idx] = possible_anchors_dict[pred_obj_name][0].object_id\n",
    "            unique_anchor_flag = True\n",
    "            unique_anchor_counter += 1\n",
    "\n",
    "    # Assign the hard objs (Several objects) using the geometry info:\n",
    "    remaining_indices = [c for c, x in enumerate(pred_anchor) if x is None]  # find indices of hard objs\n",
    "    objs_center = [None] * len(pred_objs_name)\n",
    "    # Loop on the remaining objects:\n",
    "    for idx in remaining_indices:\n",
    "        hard_counter += 1\n",
    "        pred_obj_name = pred_objs_name[idx]\n",
    "        if pred_obj_name[0] == '*':  # Skip object that don't have a bbox\n",
    "            continue\n",
    "\n",
    "        # check unique obj may be after the target removal the obj become unique.\n",
    "        if len(possible_anchors_dict[pred_obj_name]) == 1:\n",
    "            pred_anchor[idx] = possible_anchors_dict[pred_obj_name][0]\n",
    "            all_scene_anchors[i][idx] = possible_anchors_dict[pred_obj_name][0].object_id\n",
    "            unique_anchor_flag = True\n",
    "            unique_anchor_counter += 1\n",
    "            continue\n",
    "\n",
    "        # 1- Get the center of each object:\n",
    "        # 1.1-unassigned objs of same class center\n",
    "        unassigned_anchors_center = []\n",
    "        for anchor in possible_anchors_dict[pred_obj_name]:  # unassigned objs\n",
    "            obj_pc = scenes_dict[scan_id].pc[anchor.points]\n",
    "            unassigned_anchors_center.append(np.mean(obj_pc, axis=0))\n",
    "            # w, l, h = get3d_box_from_pcs(obj_pc)\n",
    "        # 1.2-assigned objs center\n",
    "        known_indices = [c for c, x in enumerate(pred_anchor) if x is not None]  # find indices of hard objs\n",
    "        known_centers = []\n",
    "        for known_idx in known_indices:\n",
    "            obj_pc = scenes_dict[scan_id].pc[pred_anchor[known_idx].points]\n",
    "            known_centers.append((get3d_box_center_from_pcs(obj_pc), pred_anchor[known_idx].instance_label))\n",
    "\n",
    "        # 2- Get the relationship between objects:\n",
    "        # get relationships containing the current obj:\n",
    "        relations = get_relationship_conatining_obj(i, relations_df, pred_obj_name, target=df.instance_type[i])\n",
    "        #print(\"relations = \", relations)\n",
    "        # 1st case for random:\n",
    "        if len(relations) == 0:\n",
    "            # all_scene_anchors[i].append(-1)\n",
    "            empty_relation_counter += 1\n",
    "            empty_relation_flag = True\n",
    "            rand_idx = np.random.randint(0,len(possible_anchors_dict[pred_obj_name]))\n",
    "            pred_anchor[idx] = possible_anchors_dict[pred_obj_name][rand_idx]\n",
    "            # del unassigned_anchors_center[rand_idx]\n",
    "            all_scene_anchors[i][idx] = pred_anchor[idx].object_id\n",
    "        deleted_objs = 0\n",
    "        found = False\n",
    "        # loop over the relations and get which one of the relations has a known object in the second value of the tuple\n",
    "        for relation_tuple in relations:\n",
    "            if found:\n",
    "                break\n",
    "            relation, obj2, flag = relation_tuple\n",
    "            # Get the closest relation mapping from mapped_relation using get_closest_relation_mapping\n",
    "            closest_relation = get_relationship_between_2_objs(relation, mapped_relation.keys())\n",
    "            obj2_centers = [c[0] for c in known_centers if c[1] == obj2]\n",
    "            if closest_relation == '' or len(obj2_centers) == 0:\n",
    "                continue\n",
    "            \n",
    "            relation_mapped = mapped_relation[closest_relation]\n",
    "            for known_center in obj2_centers: # Eslam: check is\n",
    "                if len(unassigned_anchors_center) == 0:\n",
    "                    break\n",
    "                if flag:\n",
    "                    approx_anchor = relation_fn_dict[relation_mapped](known_center, unassigned_anchors_center)\n",
    "                else:\n",
    "                    approx_anchor = reverse_relation_fn_dict[relation_mapped](known_center, unassigned_anchors_center)\n",
    "                # get the index of the chosen center with regards to unassigned_anchors_center:\n",
    "                correct_counter += 1\n",
    "                if approx_anchor is not None:\n",
    "                    chosen_center_idx = np.argmin(np.linalg.norm(np.array(unassigned_anchors_center) - np.array(approx_anchor), axis=1))\n",
    "                    del unassigned_anchors_center[chosen_center_idx]\n",
    "                    chosen_center_idx = chosen_center_idx + deleted_objs\n",
    "                    deleted_objs += 1\n",
    "                    found = True\n",
    "                    pred_anchor[idx] = possible_anchors_dict[pred_obj_name][chosen_center_idx]\n",
    "                    all_scene_anchors[i][idx] = possible_anchors_dict[pred_obj_name][chosen_center_idx].object_id\n",
    "                else:\n",
    "                    # the relation is not valid (e.g., no object is following the relation)\n",
    "                    # So get the nearest:\n",
    "                    approx_anchor = relation_fn_dict['near'](known_center, unassigned_anchors_center)\n",
    "                    chosen_center_idx = np.argmin(np.linalg.norm(np.array(unassigned_anchors_center) - np.array(approx_anchor), axis=1))\n",
    "                    del unassigned_anchors_center[chosen_center_idx]\n",
    "                    found = True\n",
    "                    chosen_center_idx = chosen_center_idx + deleted_objs\n",
    "                    deleted_objs += 1\n",
    "                    pred_anchor[idx] = possible_anchors_dict[pred_obj_name][chosen_center_idx]\n",
    "                    all_scene_anchors[i][idx] = possible_anchors_dict[pred_obj_name][chosen_center_idx].object_id\n",
    "                break\n",
    "    \n",
    "        # 2nd case for random:\n",
    "        # If u can not find object in all relations so take the nearest one (Random guess)\n",
    "        if pred_anchor[idx] == None:\n",
    "            empty_relation_counter += 1\n",
    "            rand_idx = np.random.randint(0,len(possible_anchors_dict[pred_obj_name]))\n",
    "            pred_anchor[idx] = possible_anchors_dict[pred_obj_name][rand_idx]\n",
    "            all_scene_anchors[i][idx] = pred_anchor[idx].object_id\n",
    "            empty_relation_flag = True\n",
    "                        \n",
    "print(\"---------------------\")\n",
    "print(\"num of all objects: \", counter)\n",
    "print(\"num of Target objects: \", (target_counter/counter)*100)\n",
    "print(\"num of Unique objects: \", (unique_anchor_counter/counter)*100)\n",
    "print(\"num of Geometry objects: \", (correct_counter/counter)*100)\n",
    "print(\"num of Random objects: \", (empty_relation_counter/counter)*100)\n",
    "print(\"num of No box objects: \", (no_box_counter/counter)*100)\n",
    "print(\"num of No anchors objects: \", (empty_anchor_counter/counter)*100)\n",
    "print(\"---------------------\")\n",
    "print(\"num of all objects: \", counter)\n",
    "print(\"num of Target objects: \", target_counter)\n",
    "print(\"num of Unique objects: \", unique_anchor_counter)\n",
    "print(\"num of Geometry objects: \", correct_counter)\n",
    "print(\"num of Random objects: \", empty_relation_counter)\n",
    "print(\"num of No box objects: \", no_box_counter)\n",
    "print(\"num of No anchors objects: \", empty_anchor_counter)\n",
    "print(\"---------------------\")\n",
    "print(\"Check the total number: \", (target_counter + unique_anchor_counter + correct_counter + empty_relation_counter + no_box_counter + empty_anchor_counter)==counter)\n",
    "print(\"---------------------\")\n",
    "print(\"The Assigned anchors are: \", len(pred_anchor))\n",
    "\n",
    "df['path'] = all_scenes_refined_path\n",
    "df['num_anchors'] = all_scenes_num_anchors\n",
    "\n",
    "for obj_count, obj in enumerate(pred_anchor):\n",
    "    print(\"obj = \", obj)\n",
    "    if obj:  # as sometimes it is none\n",
    "        print(\"Obj \", obj_count, \": \", obj.instance_label, obj.object_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the new file:\n",
    "anchor_ids = []\n",
    "for i in range(len(df)):\n",
    "    anchor_ids.append(all_scene_anchors[i])\n",
    "\n",
    "df['anchor_ids'] = anchor_ids\n",
    "df.to_csv('nr3d_cot_ref_paraphrases_num_anchors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_scene_anchors_normal_objs.json', 'w') as fp:\n",
    "    json.dump(all_scene_anchors, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_csv_as_list_dict(csv_pth):\n",
    "    rows = []\n",
    "    with open(csv_pth, 'r') as csvfile:\n",
    "        for row in csv.DictReader(csvfile, delimiter=','):\n",
    "            rows.append(row)\n",
    "    return rows\n",
    "\n",
    "\n",
    "def clean_obj_path(rows):\n",
    "    print(\"Cleaning the objects path......\")\n",
    "    for row in rows:\n",
    "        clean_objs = []\n",
    "        print(row[\"path\"])\n",
    "        if \"'\" in row[\"path\"]:\n",
    "            objects = row[\"path\"].split(',')\n",
    "            for obj in objects:\n",
    "                clean_objs.append(obj.strip().split(\"'\")[1])\n",
    "        row[\"path\"] = clean_objs\n",
    "    print(\"Finish the cleaning.\")\n",
    "    return rows\n",
    "\n",
    "\n",
    "def get_logical_pth_lang(data_dict):\n",
    "    \"\"\"\n",
    "    Convert the string into readable list\n",
    "    \"\"\"\n",
    "    for idx, row in enumerate(data_dict[\"path\"]):\n",
    "        clean_objs = []\n",
    "        if \"'\" in row:\n",
    "            objects = row.split(',')\n",
    "            for obj in objects:\n",
    "                obj = obj.strip().split(\"'\")[1]\n",
    "                if '*' in obj:\n",
    "                    obj = obj[1:]\n",
    "                clean_objs.append(obj)\n",
    "        data_dict[\"path\"][idx] = clean_objs\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def clean_paraphrased(data_dict):\n",
    "    \"\"\"\n",
    "    Convert the string into readable list\n",
    "    \"\"\"\n",
    "    for idx, row in enumerate(data_dict[\"paraphrases\"]):\n",
    "        clean_objs = []\n",
    "        if '\"' in row:\n",
    "            objects = row.split(',')\n",
    "            for obj in objects:\n",
    "                obj = obj.strip().split('\"')[1]\n",
    "                clean_objs.append(obj)\n",
    "        data_dict[\"paraphrases\"][idx] = clean_objs\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def unique(list1):\n",
    "    x = np.array(list1)\n",
    "    return np.unique(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrem/anaconda3/envs/artemis-m2/lib/python3.7/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.43247476086066\n",
      "53.80815844637737\n",
      "23.046526757101898\n",
      "4.7851962508734305\n",
      "0.9276437847866419\n"
     ]
    }
   ],
   "source": [
    "# Check percentages of number of anchors:\n",
    "# ----------------------------------------\n",
    "rows = pd.read_csv(\"nr3d_cot_ref_paraphrases_num_anchors.csv\")\n",
    "rows = get_logical_pth_lang(rows)\n",
    "num_objs_per_sentences = []\n",
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "count_4 = 0\n",
    "count_5 = 0\n",
    "for row in rows[\"path\"]:\n",
    "    num_objs_per_sentences.append(len(row))\n",
    "for num in num_objs_per_sentences:\n",
    "    if num ==1:\n",
    "        count_1 +=1\n",
    "    elif num ==2:\n",
    "        count_2 +=1\n",
    "    elif num ==3:\n",
    "        count_3 +=1\n",
    "    elif num ==4:\n",
    "        count_4 +=1\n",
    "    elif num >=5:\n",
    "        count_5 +=1    \n",
    "print(100*count_1/len(num_objs_per_sentences))    \n",
    "print(100*count_2/len(num_objs_per_sentences))    \n",
    "print(100*count_3/len(num_objs_per_sentences))    \n",
    "print(100*count_4/len(num_objs_per_sentences))    \n",
    "print(100*count_5/len(num_objs_per_sentences))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrem/anaconda3/envs/artemis-m2/lib/python3.7/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.786810592005397\n",
      "13.408669252825097\n",
      "24.697009854709297\n",
      "14.534692271241436\n",
      "8.646764490920335\n",
      "22.926053538298437\n"
     ]
    }
   ],
   "source": [
    "# Check percentages of number of anchors:\n",
    "# ----------------------------------------\n",
    "rows = pd.read_csv(\"nr3d_cot_ref_paraphrases_num_anchors.csv\")\n",
    "rows = clean_paraphrased(rows)\n",
    "num_paraphrased_per_sentences = []\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "count_4 = 0\n",
    "count_5 = 0\n",
    "for row in rows[\"paraphrases\"]:\n",
    "    num_objs_per_sentences.append(len(row))\n",
    "for num in num_objs_per_sentences:\n",
    "    if num ==0:\n",
    "        count_0 +=1\n",
    "    elif num ==1:\n",
    "        count_1 +=1\n",
    "    elif num ==2:\n",
    "        count_2 +=1\n",
    "    elif num ==3:\n",
    "        count_3 +=1\n",
    "    elif num ==4:\n",
    "        count_4 +=1\n",
    "    elif num >=5:\n",
    "        count_5 +=1    \n",
    "print(100*count_0/len(num_objs_per_sentences))    \n",
    "print(100*count_1/len(num_objs_per_sentences))    \n",
    "print(100*count_2/len(num_objs_per_sentences))    \n",
    "print(100*count_3/len(num_objs_per_sentences))    \n",
    "print(100*count_4/len(num_objs_per_sentences))    \n",
    "print(100*count_5/len(num_objs_per_sentences))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the original length is:  77140\n",
      "the length of item that has one relation is:  16743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16743it [03:36, 77.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check how many samples have one relation:\n",
    "relation_rows = pd.read_csv(\"relations_parsed.csv\")\n",
    "print(\"the original length is: \", len(relation_rows))\n",
    "relation_rows = relation_rows.drop_duplicates(subset=['org_utterance'], keep=False)\n",
    "print(\"the length of item that has one relation is: \", len(relation_rows))\n",
    "\n",
    "# make the utterance lower:\n",
    "rows = pd.read_csv(\"nr3d_cot_ref_paraphrases_num_anchors.csv\")\n",
    "\"\"\"\n",
    "for idx, row in enumerate(rows[\"utterance\"]):\n",
    "    rows[\"utterance\"][idx] = row.lower()\n",
    "\"\"\"\n",
    "\n",
    "# Check how many samples have one relation and one anchor only:\n",
    "unique_rel_anchor_data = pd.DataFrame(columns = rows.columns)\n",
    "unique_rel_anchor_counter = 0\n",
    "objects, relations, subjects = [], [], []\n",
    "for index, relation_row in tqdm(relation_rows.iterrows()):\n",
    "    #print(relation_row['org_utterance'])\n",
    "    #print(len(rows[rows.utterance.str.contains(relation_row['org_utterance'],case=False)]))\n",
    "    index = int(index)\n",
    "    mask = rows[rows.utterance.str.lower().isin([relation_row['org_utterance']])]\n",
    "    if len(mask) == 1:\n",
    "        if (mask.num_anchors.values[0] == 1) and (mask.anchor_ids.values[0][0] != -1):\n",
    "            if (type(relation_row.object) == str) and (type(relation_row.relation) == str) and (type(relation_row.subject) == str):\n",
    "                objects.append(relation_row.object)\n",
    "                relations.append(relation_row.relation)\n",
    "                subjects.append(relation_row.subject)\n",
    "                unique_rel_anchor_data = unique_rel_anchor_data.append(mask)\n",
    "                unique_rel_anchor_counter += 1\n",
    "print(unique_rel_anchor_counter)\n",
    "unique_rel_anchor_data['object'] = objects\n",
    "unique_rel_anchor_data['relation'] = relations\n",
    "unique_rel_anchor_data['subject'] = subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rel_anchor_data.to_csv('nr3d_cot_unique_rel_anchor_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1314\n",
      "1074\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "unique_relations = unique(relations)\n",
    "print(len(unique_relations))\n",
    "\n",
    "with open('mapped_relation.json') as f:\n",
    "    mapped_relation = json.load(f)\n",
    "\n",
    "found_c = 0\n",
    "unique_rel_map_dict = {}\n",
    "for uni_rel in unique_relations:\n",
    "    found_flag = False\n",
    "    # Exact matching:\n",
    "    for mapped_rel in mapped_relation.keys():\n",
    "        if mapped_rel == uni_rel.lower():\n",
    "            found_rel = mapped_rel\n",
    "            found_c += 1\n",
    "            found_flag = True\n",
    "            break\n",
    "    if not found_flag:  # Not exact matching\n",
    "        found_rel = []\n",
    "        for mapped_rel in mapped_relation.keys():\n",
    "            if mapped_rel in uni_rel.lower():\n",
    "                found_rel.append(mapped_rel)\n",
    "        if len(found_rel):\n",
    "            found_rel = max(found_rel, key=len)\n",
    "            found_c += 1\n",
    "            found_flag = True\n",
    "    \n",
    "    # If still can't get it, assume near:\n",
    "    if not found_flag:\n",
    "        found_rel = \"near\"\n",
    "\n",
    "    unique_rel_map_dict[uni_rel] = found_rel\n",
    "print(found_c)\n",
    "with open('unique_rel_map_dict.json', 'w') as fp:\n",
    "    json.dump(unique_rel_map_dict, fp)\n",
    "\n",
    "# Create another dict for opposite relations:\n",
    "# -------------------------------------------\n",
    "with open('mapped_relation_opposite.json') as f:\n",
    "    opposite_dict = json.load(f)\n",
    "for unique_rel, mapped_rel in unique_rel_map_dict.items():\n",
    "    unique_rel_map_dict[unique_rel] = opposite_dict[mapped_rel]\n",
    "\n",
    "with open('unique_rel_map_dict_opposite.json', 'w') as fp:\n",
    "    json.dump(unique_rel_map_dict, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1:  41503\n",
      "File 2:  11048\n",
      "Index(['Unnamed: 0', 'Unnamed: 0.1', 'assignmentid', 'stimulus_id',\n",
      "       'utterance', 'correct_guess', 'speaker_id', 'listener_id', 'scan_id',\n",
      "       'instance_type', 'target_id', 'tokens', 'dataset',\n",
      "       'mentions_target_class', 'uses_object_lang', 'uses_spatial_lang',\n",
      "       'uses_color_lang', 'uses_shape_lang', 'path', 'anchor_ids',\n",
      "       'paraphrases', 'num_anchors', 'Unnamed: 0_y', 'Unnamed: 0.1_y',\n",
      "       'Unnamed: 0.1.1', 'assignmentid_y', 'stimulus_id_y', 'correct_guess_y',\n",
      "       'speaker_id_y', 'listener_id_y', 'scan_id_y', 'instance_type_y',\n",
      "       'target_id_y', 'tokens_y', 'dataset_y', 'mentions_target_class_y',\n",
      "       'uses_object_lang_y', 'uses_spatial_lang_y', 'uses_color_lang_y',\n",
      "       'uses_shape_lang_y', 'path_y', 'anchor_ids_y', 'paraphrases_y',\n",
      "       'num_anchors_y', 'object', 'relation', 'subject'],\n",
      "      dtype='object')\n",
      "Merged File :  41503\n",
      "nan\n",
      "facing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d_set = pd.read_csv(\"/home/abdelrem/3d_codes/CoT3D_VG/extract_anchors/nr3d_cot_ref_paraphrases_num_anchors.csv\")\n",
    "print(\"File 1: \", len(d_set))\n",
    "unique_rel_df = pd.read_csv(\"/home/abdelrem/3d_codes/CoT3D_VG/extract_anchors/nr3d_cot_unique_rel_anchor_data.csv\")\n",
    "print(\"File 2: \", len(unique_rel_df))\n",
    "d_set = pd.merge(d_set, unique_rel_df, how='outer', on=['utterance'], suffixes=('', '_y'))\n",
    "print(d_set.columns)\n",
    "print(\"Merged File : \", len(d_set))\n",
    "print(d_set.relation[0])\n",
    "print(d_set.relation[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'facing'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(d_set.relation[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in RAM 707 scans\n",
      "524 instance classes exist in these scans\n",
      "#train/test scans: 1201 / 312\n"
     ]
    }
   ],
   "source": [
    "# Test Training Nr + Sr\n",
    "import numpy as np\n",
    "import six\n",
    "import string\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import logging\n",
    "import os.path as osp\n",
    "import pathlib\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from six.moves import cPickle\n",
    "from six.moves import range\n",
    "\n",
    "\n",
    "def load_scan_related_data(preprocessed_scannet_file, verbose=True, add_pad=True, add_no_obj=False):\n",
    "    _, all_scans = unpickle_data(preprocessed_scannet_file)\n",
    "    if verbose:\n",
    "        print('Loaded in RAM {} scans'.format(len(all_scans)))\n",
    "\n",
    "    instance_labels = set()\n",
    "    for scan in all_scans:\n",
    "        idx = np.array([o.object_id for o in scan.three_d_objects])\n",
    "        instance_labels.update([o.instance_label for o in scan.three_d_objects])\n",
    "        assert np.all(idx == np.arange(len(idx)))  # assert the list of objects-ids -is- the range(n_objects).\n",
    "                                                   # because we use this ordering when we sample objects from a scan.\n",
    "    all_scans = {scan.scan_id: scan for scan in all_scans}  # place scans in dictionary\n",
    "\n",
    "\n",
    "    class_to_idx = {}\n",
    "    i = 0\n",
    "    for el in sorted(instance_labels):\n",
    "        class_to_idx[el] = i\n",
    "        i += 1\n",
    "\n",
    "    if verbose:\n",
    "        print('{} instance classes exist in these scans'.format(len(class_to_idx)))\n",
    "\n",
    "    # Add the pad class needed for object classification\n",
    "    if add_pad:\n",
    "        class_to_idx['pad'] = len(class_to_idx)\n",
    "\n",
    "    if add_no_obj:\n",
    "        class_to_idx['no_obj'] = len(class_to_idx)\n",
    "\n",
    "    scans_split = scannet_official_train_val()\n",
    "\n",
    "    return all_scans, scans_split, class_to_idx\n",
    "\n",
    "\n",
    "def read_lines(file_name):\n",
    "    trimmed_lines = []\n",
    "    with open(file_name) as fin:\n",
    "        for line in fin:\n",
    "            trimmed_lines.append(line.rstrip())\n",
    "    return trimmed_lines\n",
    "\n",
    "\n",
    "def scannet_official_train_val(valid_views=None, verbose=True):\n",
    "    \"\"\"\n",
    "    :param valid_views: None or list like ['00', '01']\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    pre_fix = \"/home/abdelrem/3d_codes/CoT3D_VG/refering_codes/MVT-3DVG/referit3d\"\n",
    "    train_split = osp.join(pre_fix, 'data/scannet/splits/official/v2/scannetv2_train.txt')\n",
    "    train_split = read_lines(train_split)\n",
    "    test_split = osp.join(pre_fix, 'data/scannet/splits/official/v2/scannetv2_val.txt')\n",
    "    test_split = read_lines(test_split)\n",
    "\n",
    "    if valid_views is not None:\n",
    "        train_split = [sc for sc in train_split if sc[-2:] in valid_views]\n",
    "        test_split = [sc for sc in test_split if sc[-2:] in valid_views]\n",
    "\n",
    "    if verbose:\n",
    "        print('#train/test scans:', len(train_split), '/', len(test_split))\n",
    "\n",
    "    scans_split = dict()\n",
    "    scans_split['train'] = set(train_split)\n",
    "    scans_split['test'] = set(test_split)\n",
    "    return scans_split\n",
    "\n",
    "\n",
    "def unpickle_data(file_name, python2_to_3=False):\n",
    "    \"\"\"\n",
    "    Restore data previously saved with pickle_data().\n",
    "    :param file_name: file holding the pickled data.\n",
    "    :param python2_to_3: (boolean), if True, pickle happened under python2x, unpickling under python3x.\n",
    "    :return: an generator over the un-pickled items.\n",
    "    Note, about implementing the python2_to_3 see\n",
    "        https://stackoverflow.com/questions/28218466/unpickling-a-python-2-object-with-python-3\n",
    "    \"\"\"\n",
    "    in_file = open(file_name, 'rb')\n",
    "    if python2_to_3:\n",
    "        size = cPickle.load(in_file, encoding='latin1')\n",
    "    else:\n",
    "        size = cPickle.load(in_file)\n",
    "\n",
    "    for _ in range(size):\n",
    "        if python2_to_3:\n",
    "            yield cPickle.load(in_file, encoding='latin1')\n",
    "        else:\n",
    "            yield cPickle.load(in_file)\n",
    "    in_file.close()\n",
    "\n",
    "\n",
    "\n",
    "def create_sr3d_classes_2_idx(json_pth):\n",
    "    with open(json_pth) as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    instance_labels = set()\n",
    "    instance_labels.update([k for k in data])\n",
    "\n",
    "    class_to_idx = {}\n",
    "    i = 0\n",
    "    for el in sorted(instance_labels):\n",
    "        class_to_idx[el] = i\n",
    "        i += 1\n",
    "\n",
    "    class_to_idx['pad'] = len(class_to_idx)\n",
    "    class_to_idx['no_obj'] = len(class_to_idx)\n",
    "\n",
    "    return class_to_idx\n",
    "\n",
    "\n",
    "\n",
    "scannet_file = \"/home/abdelrem/3d_codes/scannet_dataset/scannet/scan_4_nr3d_org/keep_all_points_00_view_with_global_scan_alignment/keep_all_points_00_view_with_global_scan_alignment.pkl\"\n",
    "predict_lang_anchors = True\n",
    "anchors = \"cot\"\n",
    "all_scans_in_dict, scans_split, class_to_idx = load_scan_related_data(scannet_file, add_no_obj=anchors != 'none' or predict_lang_anchors)\n",
    "class_to_idx = create_sr3d_classes_2_idx(json_pth=\"referit3d/data/mappings/scannet_instance_class_to_semantic_class.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrem/anaconda3/envs/artemis/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping utterances without explicit mention to the target class 41503->37842\n",
      "95-th percentile of token length for remaining (training) data is: 24.0\n",
      "Dropping utterances with more than 24 tokens, 37842->36201\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "def get_logical_pth_lang(data_dict):\n",
    "    \"\"\"\n",
    "    Convert the string into readable list\n",
    "    \"\"\"\n",
    "    for idx, row in enumerate(data_dict[\"path\"]):\n",
    "        clean_objs = []\n",
    "        if \"'\" in row:\n",
    "            objects = row.split(',')\n",
    "            for obj in objects:\n",
    "                obj = obj.strip().split(\"'\")[1]\n",
    "                if '*' in obj:\n",
    "                    obj = obj[1:]\n",
    "                clean_objs.append(obj)\n",
    "        data_dict[\"path\"][idx] = clean_objs\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def decode_stimulus_string(s):\n",
    "        \"\"\"\n",
    "        Split into scene_id, instance_label, # objects, target object id,\n",
    "        distractors object id.\n",
    "\n",
    "        :param s: the stimulus string\n",
    "        \"\"\"\n",
    "        if len(s.split('-', maxsplit=4)) == 4:\n",
    "            scene_id, instance_label, n_objects, target_id = \\\n",
    "                s.split('-', maxsplit=4)\n",
    "            distractors_ids = \"\"\n",
    "        else:\n",
    "            scene_id, instance_label, n_objects, target_id, distractors_ids = \\\n",
    "                s.split('-', maxsplit=4)\n",
    "\n",
    "        instance_label = instance_label.replace('_', ' ')\n",
    "        n_objects = int(n_objects)\n",
    "        target_id = int(target_id)\n",
    "        distractors_ids = [int(i) for i in distractors_ids.split('-') if i != '']\n",
    "        assert len(distractors_ids) == n_objects - 1\n",
    "\n",
    "        return scene_id, instance_label, n_objects, target_id, distractors_ids\n",
    "\n",
    "\n",
    "referit_csv = \"/home/abdelrem/3d_codes/CoT3D_VG/extract_anchors/nr3d_cot_ref_paraphrases_num_anchors.csv\"\n",
    "textaug_paraphrase_percentage = 0\n",
    "mentions_target_class_only = True\n",
    "anchors = 'cot'\n",
    "max_seq_len = 24\n",
    "augment_with_sr3d = \"/home/abdelrem/3d_codes/scannet_dataset/scannet/sr3d.csv\"\n",
    "referit_data = pd.read_csv(referit_csv)\n",
    "\n",
    "is_nr = True if 'nr' in referit_csv else False\n",
    "if is_nr and (anchors != 'none'):\n",
    "    referit_data = get_logical_pth_lang(referit_data)\n",
    "\n",
    "if textaug_paraphrase_percentage:\n",
    "    referit_data = clean_paraphrased(referit_data)\n",
    "\n",
    "if mentions_target_class_only:\n",
    "    n_original = len(referit_data)\n",
    "    referit_data = referit_data[referit_data['mentions_target_class']]\n",
    "    referit_data.reset_index(drop=True, inplace=True)\n",
    "    print('Dropping utterances without explicit '\n",
    "            'mention to the target class {}->{}'.format(n_original, len(referit_data)))\n",
    "\n",
    "keys = ['tokens', 'instance_type', 'scan_id', 'dataset', 'target_id', 'utterance', 'stimulus_id']\n",
    "added_keys = ['path', 'anchor_ids', 'num_anchors', 'paraphrases'] if is_nr else ['anchors_types', 'anchor_ids']\n",
    "keys += added_keys\n",
    "referit_data = referit_data[keys]\n",
    "referit_data.tokens = referit_data['tokens'].apply(literal_eval)\n",
    "\n",
    "# Add the is_train data to the pandas data frame (needed in creating data loaders for the train and test)\n",
    "is_train = referit_data.scan_id.apply(lambda x: x in scans_split['train'])\n",
    "referit_data['is_train'] = is_train\n",
    "\n",
    "# Trim data based on token length\n",
    "train_token_lens = referit_data.tokens[is_train].apply(lambda x: len(x))\n",
    "print('{}-th percentile of token length for remaining (training) data'\n",
    "        ' is: {:.1f}'.format(95, np.percentile(train_token_lens, 95)))\n",
    "n_original = len(referit_data)\n",
    "referit_data = referit_data[referit_data.tokens.apply(lambda x: len(x) <= max_seq_len)]\n",
    "referit_data.reset_index(drop=True, inplace=True)\n",
    "print('Dropping utterances with more than {} tokens, {}->{}'.format(max_seq_len, n_original, len(referit_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36201\n",
      "Index(['tokens', 'instance_type', 'scan_id', 'dataset', 'target_id',\n",
      "       'utterance', 'stimulus_id', 'path', 'anchor_ids', 'num_anchors',\n",
      "       'paraphrases', 'is_train'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(referit_data))\n",
    "print(referit_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Sr3D as augmentation.\n",
      "Dataset-size before augmentation: 36201\n",
      "Dataset-size after augmentation: 102047\n",
      "Index(['anchor_ids', 'anchors_types', 'dataset', 'instance_type', 'is_train',\n",
      "       'num_anchors', 'paraphrases', 'path', 'scan_id', 'stimulus_id',\n",
      "       'target_id', 'tokens', 'utterance'],\n",
      "      dtype='object')\n",
      "(mean) Random guessing among target-class test objects 0.3814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelrem/anaconda3/envs/artemis/lib/python3.7/site-packages/ipykernel_launcher.py:14: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# do this last, so that all the previous actions remain unchanged\n",
    "if augment_with_sr3d is not None:\n",
    "    print('Adding Sr3D as augmentation.')\n",
    "    sr3d = pd.read_csv(augment_with_sr3d)\n",
    "    sr3d.tokens = sr3d['tokens'].apply(literal_eval)\n",
    "    is_train = sr3d.scan_id.apply(lambda x: x in scans_split['train'])\n",
    "    sr3d['is_train'] = is_train\n",
    "    sr3d = sr3d[is_train]\n",
    "    # Eslam:\n",
    "    keys = ['tokens', 'instance_type', 'scan_id', 'dataset', 'target_id', 'utterance', 'stimulus_id', 'anchors_types', 'anchor_ids', 'is_train']\n",
    "    sr3d = sr3d[keys]\n",
    "    # sr3d = sr3d[referit_data.columns]\n",
    "    print('Dataset-size before augmentation:', len(referit_data))\n",
    "    referit_data = pd.concat([referit_data, sr3d], axis=0)\n",
    "    referit_data.reset_index(inplace=True, drop=True)\n",
    "    print('Dataset-size after augmentation:', len(referit_data))\n",
    "    print(referit_data.columns)\n",
    "\n",
    "context_size = referit_data[~referit_data.is_train].stimulus_id.apply(lambda x: decode_stimulus_string(x)[2])\n",
    "print('(mean) Random guessing among target-class test objects {:.4f}'.format( (1 / context_size).mean() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary ~: 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19247/3481620290.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreferit_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mreferit_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstimulus_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/artemis/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__invert__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__invert__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary ~: 'float'"
     ]
    }
   ],
   "source": [
    "referit_data[~referit_data.is_train].stimulus_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "707"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_scans_in_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
