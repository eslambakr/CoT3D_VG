{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtlabel_dataset import GTLabelDataset\n",
    "\n",
    "scan_dir = \"/home/abdelrem/3d_codes/vil3d_preprocessed_data/scan_data\"\n",
    "anno_file = \"/home/abdelrem/3d_codes/vil3d_preprocessed_data/annotations/bert_tokenized/nr3d.jsonl\"\n",
    "category_file =  \"/home/abdelrem/3d_codes/vil3d_preprocessed_data/annotations/meta_data/scannetv2_raw_categories.json\"\n",
    "cat2vec_file = \"/home/abdelrem/3d_codes/vil3d_preprocessed_data/annotations/meta_data/cat2glove42b.json\"\n",
    "\n",
    "trn_scan_split = \"/home/abdelrem/3d_codes/vil3d_preprocessed_data/annotations/splits/scannetv2_train.txt\"\n",
    "val_scan_split = \"/home/abdelrem/3d_codes/vil3d_preprocessed_data/annotations/splits/scannetv2_val.txt\"\n",
    "tst_scan_split = \"/home/abdelrem/3d_codes/vil3d_preprocessed_data/annotations/splits/scannetv2_test.txt\"\n",
    "\n",
    "max_txt_len = 50\n",
    "max_obj_len = 80\n",
    "keep_background = False\n",
    "random_rotate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "nr3d_csv_pth = \"/home/abdelrem/3d_codes/CoT3D_VG/extract_anchors/nr3d_cot_ref_paraphrases_num_anchors.csv\"\n",
    "nr3d_cot_dict = pd.read_csv(nr3d_csv_pth).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Unnamed: 0', 'Unnamed: 0.1', 'assignmentid', 'stimulus_id', 'utterance', 'correct_guess', 'speaker_id', 'listener_id', 'scan_id', 'instance_type', 'target_id', 'tokens', 'dataset', 'mentions_target_class', 'uses_object_lang', 'uses_spatial_lang', 'uses_color_lang', 'uses_shape_lang', 'path', 'anchor_ids', 'paraphrases', 'num_anchors'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr3d_cot_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rel_df = pd.read_csv(\"/home/abdelrem/3d_codes/CoT3D_VG/extract_anchors/nr3d_cot_unique_rel_anchor_data.csv\").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'assignmentid', 'stimulus_id', 'utterance', 'correct_guess', 'speaker_id', 'listener_id', 'scan_id', 'instance_type', 'target_id', 'tokens', 'dataset', 'mentions_target_class', 'uses_object_lang', 'uses_spatial_lang', 'uses_color_lang', 'uses_shape_lang', 'path', 'anchor_ids', 'paraphrases', 'num_anchors', 'object', 'relation', 'subject'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rel_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10934\n"
     ]
    }
   ],
   "source": [
    "stimulus_unique_rel_id_list = list(unique_rel_df['stimulus_id'].values())\n",
    "print(stimulus_unique_rel_id_list.index(nr3d_cot_dict['stimulus_id'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scene0586_00-trash_can-3-16-8-20'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimulus_unique_rel_id_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataset = GTLabelDataset(\n",
    "        trn_scan_split, anno_file, \n",
    "        scan_dir, category_file,\n",
    "        cat2vec_file=cat2vec_file, \n",
    "        max_txt_len=max_txt_len, max_obj_len=max_obj_len,\n",
    "        keep_background=keep_background,\n",
    "        random_rotate=random_rotate,\n",
    "        gt_scan_dir=None,\n",
    "        iou_replace_gt=0,\n",
    "        anchors_mode=\"cot\", max_anchors=7, predict_lang_anchors=True, target_aug_percentage=True, is_train=True,\n",
    "        distractor_aux_loss_flag=True, \n",
    "        data_csv_pth=\"/home/abdelrem/3d_codes/CoT3D_VG/extract_anchors/nr3d_cot_ref_paraphrases_num_anchors.csv\",\n",
    "        train_data_percent=1.0, is_nr3d=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28716"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['item_id', 'stimulus_id', 'scan_id', 'instance_type', 'target_id', 'utterance', 'tokens', 'enc_tokens', 'correct_guess', 'uses_object_lang', 'uses_spatial_lang', 'uses_color_lang', 'uses_shape_lang', 'path', 'anchor_ids', 'num_anchors'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_dataset.data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene0413_00-towel-4-32-28-29-31\n",
      "['wall', 'toilet', 'towel']\n",
      "[26, 27]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "i = 15\n",
    "print(trn_dataset.data[i]['stimulus_id'])\n",
    "print(trn_dataset.data[i]['path'])\n",
    "print(trn_dataset.data[i]['anchor_ids'])\n",
    "print(trn_dataset.data[i]['num_anchors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index =  2\n"
     ]
    }
   ],
   "source": [
    "stimulus_id_list = list(nr3d_cot_dict['stimulus_id'].values())\n",
    "index = stimulus_id_list.index(trn_dataset.data[2]['stimulus_id'])\n",
    "print(\"index = \", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item =  {'item_id': 'nr3d_000004', 'stimulus_id': 'scene0505_00-box-5-53-33-38-52-54', 'scan_id': 'scene0505_00', 'instance_type': 'box', 'target_id': 53, 'utterance': 'The box to the left hand side of the door as you are facing it', 'tokens': ['the', 'box', 'to', 'the', 'left', 'hand', 'side', 'of', 'the', 'door', 'as', 'you', 'are', 'facing', 'it'], 'enc_tokens': [101, 1996, 3482, 2000, 1996, 2187, 2192, 2217, 1997, 1996, 2341, 2004, 2017, 2024, 5307, 2009, 102], 'correct_guess': True, 'uses_object_lang': True, 'uses_spatial_lang': True, 'uses_color_lang': False, 'uses_shape_lang': False, 'path': \"['door', 'box']\", 'anchor_ids': '[8]', 'num_anchors': 1}\n"
     ]
    }
   ],
   "source": [
    "dummy_sample = trn_dataset.__getitem__(idx=3)\n",
    "#print(dummy_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj_fts =  50\n",
      "obj_lens =  50\n",
      "obj_classes =  50\n",
      "obj_classes =  tensor([ 16,  16,   6,   6,  16,  16,  16, 170,   4,  17,   1,  18,  18,  18,\n",
      "         18,  47,  47,  47,  14,  14,  14,  14, 170,  20,   8,   6,   8,  17,\n",
      "         15,  12,  14,   5,  16,  12,  69,  41,  41,  41,  17, 404,  41, 139,\n",
      "         49,  69,  12,  12,  12, 111,  29, 607])\n",
      "tgt_obj_idxs =  45\n",
      "tgt_obj_classes =  12\n",
      "obj_ids =  ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '30', '31', '32', '33', '34', '35', '37', '38', '39', '40', '41', '42', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '-1']\n",
      "anchor_objs_idxs =  tensor([ 8, 49, 49, 49, 49, 49, 49])\n",
      "anchor_objs_idxs =  7\n",
      "txt_ids =  tensor([ 101, 1996, 3482, 2000, 1996, 2187, 2192, 2217, 1997, 1996, 2341, 2004,\n",
      "        2017, 2024, 5307, 2009,  102])\n",
      "anchor_objs_classes =  [4, 607, 607, 607, 607, 607, 607]\n"
     ]
    }
   ],
   "source": [
    "print(\"obj_fts = \", len(dummy_sample['obj_fts']))\n",
    "print(\"obj_lens = \", dummy_sample['obj_lens'])\n",
    "print(\"obj_classes = \", len(dummy_sample['obj_classes']))\n",
    "print(\"obj_classes = \", dummy_sample['obj_classes'])\n",
    "print(\"tgt_obj_idxs = \", dummy_sample['tgt_obj_idxs'])\n",
    "print(\"tgt_obj_classes = \", dummy_sample['tgt_obj_classes'])\n",
    "print(\"obj_ids = \", dummy_sample['obj_ids'])\n",
    "print(\"anchor_objs_idxs = \", dummy_sample['anchor_objs_idxs'])\n",
    "print(\"anchor_objs_idxs = \", len(dummy_sample['anchor_objs_idxs']))\n",
    "print(\"txt_ids = \", dummy_sample['txt_ids'])\n",
    "print(\"anchor_objs_classes = \", dummy_sample['anchor_objs_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utterance =  The box to the left hand side of the door as you are facing it\n",
      "box\n",
      "door\n",
      "no_obj\n"
     ]
    }
   ],
   "source": [
    "print(\"utterance = \", dummy_sample['utterance'])\n",
    "print(trn_dataset.int2cat[dummy_sample['tgt_obj_classes']])\n",
    "print(trn_dataset.int2cat[dummy_sample['anchor_objs_classes'][0]])\n",
    "print(trn_dataset.int2cat[dummy_sample['anchor_objs_classes'][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 607, 607, 607, 607, 607, 607]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_sample['anchor_objs_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'towel', 'hanging', 'above', 'the', 'tub', 'and', 'on', 'the', 'left', 'hand', 'side']\n",
      "[101, 1996, 10257, 5689, 2682, 1996, 14366, 1998, 2006, 1996, 2187, 2192, 2217, 102]\n"
     ]
    }
   ],
   "source": [
    "print(trn_dataset.data[50]['tokens'])\n",
    "print(trn_dataset.data[50]['enc_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(trn_dataset.data)):\n",
    "    trn_dataset.data[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artemis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
